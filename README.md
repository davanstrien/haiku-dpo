<h1 align="center">ðŸŒ¸ Synthetic Haiku DPO ðŸŒ¸</h1>
<p align="center"><em> Using open source LLMs to build synthetic datasets for direct preference optimization </em></p>
<p align="center">
    <img src="https://cdn-uploads.huggingface.co/production/uploads/60107b385ac3e86b3ea4fc34/nmz7lvu64BytxDvPMm1C5.png" alt="Banner for a dataset card featuring a fusion of digital and traditional Japanese elements. The design includes stylized digital prompts and haiku within text bubbles and on digital screens, set against a backdrop of delicate cherry blossoms and a serene Japanese landscape. The color scheme is dominated by soft pastel pink tones, creating a harmonious blend of modern technology and classical poetry aesthetics." width="500">
</p>

<p align="center"><em>Lines in code retreat,<br>Synthetic haiku compete,<br>Nature's rhythm, neat.<br></em></p>

## ðŸ“– About

[<img src="https://raw.githubusercontent.com/argilla-io/distilabel/main/docs/assets/distilabel-badge-light.png" alt="Built with Distilabel" width="200" height="32"/>](https://github.com/argilla-io/distilabel)

This repository contains the code used to generate the [Synthetic Haiku DPO](https://huggingface.co/datasets/argilla/synthetic-haiku-dpo) dataset, a dataset of synthetic haiku generated using [Distilabel](https://github.com/argilla-io/distilabel). 

The goal of this repo is to help the author explore the process of using synthetic data to train a model for direct preference optimization (DPO). 

